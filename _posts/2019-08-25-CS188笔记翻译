---
layout:     post
title:      伯克利CS188人工智能导论
subtitle:   笔记翻译（1）
date:       2019-8-25
author:     XYZ
header-img: img/post-bg-re-vs-ng2.jpg
catalog: true
tags:
    - Blog
---

> 翻译自UCB网络公开课CS188
>
> 已获得课程主讲教师Pieter Abbeel教授许可发布在个人博客上

# note 1

### Agents 

在人工智能中，目前的主要问题是创建一个理性（rational） agent，一个有特定目标或偏好并会针对这些目标试图执行一系列操作（actions）来得到最优解的实体。Rational agent存在于为给定的agent示例而量身定制的特定环境中。举一个简单的例子，一个西洋棋agent的环境就是它用来与对手对弈的虚拟棋盘，而对应的操作就是棋子的移动。一个环境和其中的agents一起创造了一个世界。
反射（reflex）agent不会考虑它的操作的后果，而只是根据世界的当前状态而选择一个操作。而计划（planning）agent则有一个世界模型并用这个模型来模拟执行不同的操作，远远胜过了反射agent。于是，agent就能确定操作的假想结果并选择最佳操作。这样的模拟“智能”在这个意义上符合人类在任何情况下尝试决定最佳动作的行为——预测。

### State Spaces and Search Problems 状态空间和搜索问题
为了创建一个理性计划agent，我们需要一种方法来对agent存在的环境进行数学表达。为此，我们必须正式表达一个搜索问题（search problem）——给定agent的当前状态（state）（它在环境中的配置），我们如何尽可能最好地达到一个满足目标的新状态？讲一个问题公式化需要四个前提：
	**状态空间state space**：在给定世界中所有可能的状态
	**后继函数successor function**：包含一个状态和一个操作，并计算执行该操作的代价（cost）和执行操作后世界的后继状态
	**起始状态start state**：agent最初存在时当前世界的状态
	**目标测试函数goal test**：一个函数，输入一个状态并决定它是否是一个目标状态
要解决一个搜索问题，首先要考虑它的起始状态，然后用后继函数探索它的状态空间，反复计算不同状态的后继直到得到一个目标状态，这时我们就能确定一条连接起始状态和目标状态的路径（一般称为计划路径plan）。由一个既定的策略（strategy）来决定我们考虑不同状态的顺序。很快我们将介绍策略的种类及其性能。
在我们继续讨论如何解决搜索问题之前，有必要强调一下世界状态（world state）和搜索状态（search state）的区别。世界状态包含一个给定状态的所有信息，而搜索状态仅包含对计划（主要是为了空间效率）必要的信息。我们将介绍本课程的一大亮点——吃豆人Pacman来解释这些概念。这个游戏很简单：吃豆人必须探索一个迷宫，吃掉所有的的小豆子并且不被游荡的恶灵吃掉。如果它吃了大豆子，它将在一段时间内无敌并且能吃掉恶灵赚取分数。
 
	我们来考虑这个游戏的一个变式，迷宫中只有吃豆人和豆子。在这种情况下我们能给出两种不同的搜索问题：路径规划和光盘行动pathing and eat-all-dots。路径规划需要找出从位置（x1，y1）到（x2，y2）的最佳方案，而光盘行动要求用尽可能短的时间吃掉迷宫中所有的豆子。下面分别列出了两个问题的状态、操作、后继函数和目标测试函数：

问题	路径规划	光盘行动
状态	（x，y）坐标	（x，y）坐标，豆子的布尔量
操作	东南西北	东南西北
后继函数	仅更新位置信息	更新位置和布尔量
目标测试函数	（x，y）=END？	是否所有布尔值都已为0

	路径规划的状态包含的信息比光盘行动要少，因为在光盘行动中我们必须保存一大批布尔值用来表示在给定状态中每个豆子有没有被吃掉。一个世界状态还有可能包含更多的信息，比如吃豆人走过的总距离，或者吃豆人在它的当前位置（x，y）和豆子布尔值上到达过的所有地方这些潜在的编码信息。

### State Space Size 状态空间大小
	在估算搜索问题的计算运行时间时，状态空间的大小是一个很重要的问题。这个问题几乎只能用基础计数原理（fundamental counting principle）解决：如果在一个给定的世界里有n个变量分别有x_1,x_2,…,x_n种不同的取值，那么状态的总数为x_1 x_2…x_n。我们用吃豆人来举例说明这个概念：
 
我们定义变量和它们分别的取值种数如下：
	吃豆人位置：吃豆人可以在120个不同的（x，y）坐标，而只有一个吃豆人
	吃豆人前进方向：共有东南西北四种可能
	恶灵位置：有两个恶灵，每一个都有可能在12个不同的（x，y）坐标
	豆子分布：共30个豆子，每个都要么被吃要么没有被吃
根据基础计数原理，吃豆人有120个位置，可以朝着4个方向，恶灵分布有12×12种（每个恶灵12种），豆子分布有2^30种。由此可得总状态空间大小为120×4×〖12〗^2×2^30。

### State Space Graphs and Search Trees 状态空间图和搜索树
	现在我们已经构建了状态空间的概念并用了四个部件来完整地定义了一个状态空间，我们马上就可以开始着手解决搜索问题了。现在我们缺少的最后一块拼图就是状态空间图和搜索树。
	图是由一些结点和连接结点的边构成的。这些边也会有与之相关的权重。状态空间图（state space graph）是由代表状态的结点以及从一个状态指向其后继的有向边构成的。这些边表示操作（action），而任何相关联的权重表示对应操作的代价（cost）。通常，状态空间图太大，无法存储在内存中（就算是吃豆人这样的简单例子也有大约〖10〗^13种不同状态）。不过在解决问题时从概念上记住它们就好。另一点需要注意的是，在一个状态空间图中，每一个状态仅表示一次——没必要多次表示一个状态，这一点在尝试推理搜索问题时非常有用。
	与状态空间图不同，我们要讲的下一个结构，搜索树（search trees）对于一个状态出现的次数没有限制。这是因为虽然搜索树也是一类用结点表示状态、用边表示状态之间操作的图，每个结点/状态并不仅仅代表它本身，同时也代表了状态空间图中连通起始状态和给定状态的整个路径（或计划）。观察下面的状态空间图和与其对应的搜索树：
 
	状态空间图中标红的路径(S → d → e → r → f → G)在对应的搜索树中表示为从起始状态S到标红状态G的路径。同理，状态空间图中从起始节点到其他任意节点的每条路径在搜索树中都表示为从根节点S到另一节点对应的子孙节点的路径。由于从一个状态到另一个状态通常会有多种方案，搜索树中状态会出现多次。由此，搜索树的规模大于等于对应的状态空间图。
	我们已经确定了即使是简单问题的状态空间图也有相当大的规模，于是问题来了——如果这些结构大到无法再内存中表示，我们如何对它们进行有效计算呢？答案就在后继函数中——我们只保存即刻处理的状态，并用相应的后继函数根据需求来计算新的状态。通常，搜索问题是用搜索树来解决的。在树中，我们每次观察那几个非常小心地存储选择的节点，反复地用其后继来替换节点，直到我们到达一个目标状态。有许多种方法可以用来决定在搜索树中迭代替换节点的顺序，现在我们将介绍这些方法。

### Uninformed Search 未知搜索 
	寻找从起始状态到目标状态的计划的标准协议（standard protocol）是保持来自于搜索树的部分计划的边缘（outer fringe）。通过移除一个与部分计划对应的节点（用给定的策略（strategy）来选择）并用它所有的子节点代替它，我们不断地扩展（expand）我们的边缘。用子节点代替边缘上的元素,相当于丢弃一个长度为n的计划并考虑所有源于它的长度为（n+1）的计划。我们继续这一操作，直到最终将目标从边缘移除为止。此时我们得出结论，与移除的目标状态相对应的部分计划其实就是从起始状态到目标状态的一条路径。实际上，这类算法的大多数实现都对父节点、到节点的距离和节点内部的信息进行编码。我们刚刚介绍的这一过程就是树搜索（tree search），它的伪代码如下：
 
	当我们不知道目标状态在搜索树中的的位置时，我们只能从属于未知搜索（uninformed search）的技术中选择用于树搜索的策略。我们将依次介绍三种策略：深度优先搜索DFS、广度优先搜索BFS和一致代价搜索UCS。同时，我们还会介绍它们的一些基本性质，内容如下：
	每种策略的完备性（completeness）：如果此搜索问题有解，在拥有无限计算资源的情况下，是否可以保证找到这个解？
	每种策略的最优性（optimality）：这个策略是否能保证找到通往目标状态代价最低的路径？
	分支因数b：每次将边缘节点移除并用其子节点替换时，边缘节点增加的数量为O(b)。在搜索树深度为k的一层存在O(b^k)个节点。
	最大深度m
	最浅解的深度s

### Depth-First Search深度优先搜索
	描述：深度优先搜索DFS总是选择距离起始节点最深的边缘节点来进行扩展。
	边缘表示：在边缘移除最深的节点并用它的孩子节点替换，这当然意味着现在孩子节点就成为了最深的节点——它们的深度比之前的最深节点要多1。这意味着要实现DFS，我们需要一种结构来让最近添加的对象总是有最高优先级。后进先出（LIFO）堆栈正是这样，而且它在实现DFS时通常用来表示边缘。
 
	**完备性**：深度优先搜索并不具有完备性。如果在状态空间图中存在回路，这必然意味着相应搜索树的深度将是无限的。因此，存在这样一种可能性，即DFS老实地在无限大的搜索树中搜索最深的节点而不幸地陷入僵局，注定无法找到解。
	**最优性**：深度优先搜索只是在搜索树中找到“最左边”的解，而没有考虑路径的代价，因此不是最优的。
	**时间复杂度**：在最坏情况下，深度优先搜索最终可能会搜遍整个搜索树。因此，给定一棵最大深度为m的树，DFS的时间复杂度为O(b^k)。
	**空间复杂度**：在最坏情况下，DFS在边缘上m个深度级别上都有b个节点。这是一个简单的结果，因为一旦某个父节点的b个子节点进入队列，DFS的本性在任意时间点都只允许研究任意一个子节点的一棵子树。因此，DFS的空间复杂度是O(bm)）。

### Breadth-First Search 宽度优先搜索
	描述：宽度优先搜索总是选择距离起始节点最浅（近）的边缘节点来扩展。
	边缘表示：如果我们想在较深的节点之前访问较浅的节点，我们必须按照节点的插入顺序来访问它们。因此，我们希望有一种能输出最早进入队列的对象的结构来表示我们的边缘。为此，BFS使用了一种先进先出（FIFO）队列。
 
	完备性：如果存在一个解，那么最浅节点s的深度一定是有限的，所以BFS最终一定会搜索这个深度。所以它是完备的。
	最优性：BFS一般不是最优的，因为它在选择边缘上被替换的节点时不会考虑代价问题。在所有边的代价都相等的特殊情况下BFS可以保证是最优的，因为这会让BFS退化为一致代价搜索，我们将会在下面讨论这个特殊情况。
	时间复杂度：在最坏情况下我们必须搜索1+ b +b^2+…+b^s个节点，因为我们得在从1到s每一个深度下都遍历所有节点。因此，时间复杂度是O(b^s)。
	空间复杂度：在最坏情况下，边缘所有节点都在对应最浅解的那一层。由于最浅解位于深度s处，在这一深度有O(b^s)个节点。

### Uniform Cost Search 一致代价搜索
	描述：一致代价搜索（UCS），我们的最后一种方案，总是选择距离起始节点代价最小（lowest cost）的边缘节点来扩展。
	边缘表示：为了表示UCS的边缘，通常选择基于堆的优先队列，其中给定排队节点v的权重就是从起始节点到v的路径代价，或是v的后退代价（backward cost）。直观来讲，以这种方式构建的优先队列只需重新自我洗牌就能维持我们希望得到的按照路径代价排序的顺序，因为我们移除当前代价最小的路径并用它的子路径代替了它。
	完备性：一致代价搜索是完备的。如果存在一个目标状态，它一定有一些有限长度最短路径；因此，UCS最终一定能找到这条长度最短路径。
	最优性：如果我们假设所有的边都是非负的，那么UCS也是最优的。通过构造，由于我们按照路径代价递增的顺序来搜索节点，我们肯定能找到到达一个目标状态的最低代价路径。一致代价搜索的策略与Dijkstra算法相同，主要区别在于UCS在找到一个解状态时终止，而不是找到通往所有状态的最短路径。要注意的是，如果在我们的图中有边的代价为负会导致路径上的节点长度减少，从而破坏了最优性的保证。（有关应对这种可能性的较慢的算法请参阅Bellman-Ford算法）
	时间复杂度：我们定义最优路径代价为C*，状态空间图内两节点之间最小代价为"ε" 。那么，我们得简单粗暴地遍历深度为从1到(C*)/ε范围内的所有节点，导致运行时间为O(b^(C*/ε))。
	空间复杂度：又是简单粗暴地，边缘会包括代价最低解所在层的所有节点，所以UCS空间复杂度大约为O(b^(C*/ε))。
作为对一致代价搜索的最后说明，必须注意上面列出的三种策略本质上是相同的——只是在扩展策略上有所区别，上面给出的树搜索伪代码捕捉到了它们的相似之处。

### Informed Search有信息搜索
一致代价搜索很棒，因为它兼顾了完备性和最优性。但它也可能会相当的慢，因为它在搜索一个目标时向所有方向扩展。如果我们对于我们应该搜索的方向有一定的了解，我们就能显著提高性能并更快地达到目标。这就是有信息搜索。

### Heuristics 启发式搜索
	启发式搜索是允许估计到目标状态距离的驱动力——它们是将状态作为输入并输出相应估计的函数。由这样一个函数执行的计算是专门针对所解决的搜索问题的。由于一些我们将在A*搜索中见到的原因，下面，我们一般希望启发函数是到达目标剩余距离的下界，因此启发式搜索通常是松弛问题（relaxed problems）（其中原问题的一些限制被移除了）的解决办法。回到我们的吃豆人例子，我们来考虑一下前面描述的路径规划问题。用来解决这个问题的一个通用方法是曼哈顿距离法（Manhattan Distance），对于两个点(x_1,y_1)和(x_2,y_2)的定义为：
Manhattan(x_1,y_1,x_2,y_2)=|x_1-x_2 |+|y_1-y_2 |
 
	上面的图表示了曼哈顿距离帮助解决的松弛问题——假设吃豆人想到达迷宫的左下角，它在计算了假设没有墙的情况下从吃豆人现在的位置到目标位置的距离。这个距离是松弛搜索问题中的精确（exact）距离，而相应的在实际的搜索问题中的是估计（estimated）目标距离。有了启发式搜索，在我们的agent中实现逻辑变得很简单，这使它们在决定执行哪个操作时能“偏好”在估计中离目标状态比较近的扩展状态。这个偏好的概念非常有用，并且在以下两种搜索算法中都有利用到它：贪婪搜索和A*搜索。

### Greedy Search贪婪搜索
	描述：贪婪搜索总是选择有最小启发值（lowest heuristic value）的节点来扩展，这些节点对应的是它认为最接近目标的状态。
	边缘描述：贪婪搜索的操作和UCS相同，具有优先队列边缘表示。不同之处在于，贪婪搜索使用估计前进代价（estimated forward cost），而不是计算后退代价（computed backward cost）（通往状态的路径上各边的权重之和）。
	完备性和最优性：如果存在一个目标状态，贪婪搜索无法保证能找到它，它也不是最优的，尤其是在选择了非常糟糕的启发函数的情况下。在不同场景中。它的行为通常是不可预测的，有可能一路直奔目标状态，也有可能像一个被错误引导的DFS一样并遍历所有的错误区域。
 

### A* Search  A*搜索
	描述：A*搜索总是选择有最低估计总代价（lowest estimated total cost）的边缘节点来扩展，其中总代价是指从起始节点到目标节点的全部代价。
	边缘表示：和贪婪搜索及UCS一样，A*搜索也用一个优先队列来表示它的边缘。和之前一样，唯一的区别在于优先权选择的方法。A*搜索将UCS使用的全部后退代价（到达状态的路径上各边权重之和）和贪婪搜索使用的估计前进代价（启发值）通过相加联合起来，有效地得到了从起始到目标的估计总代价（estimated total value）。由于我们想将从起始到目标的总代价最小化，这是一个很好的选择。
	完备性和最优性：在给定一个合适的启发函数（我们很快就能得到）时，A*搜索既是完备的又是最优的。它结合了目前我们发现的所有其他搜索策略的优点，兼备贪婪搜索的高搜索速度以及UCS的完备性和最优性。

### Admissibility and Consistency 可纳性和一致性
	现在我们已经讨论了启发式搜索以及它在贪婪和A*搜索中应用的，接下来我们来花些时间讨论一下一个好的启发式是由什么构成的。为此，我们首先重新定义UCS、贪婪搜索和A*中用于确定优先级队列顺序的方法，定义如下：
	g(n)：UCS计算的总后退代价函数。
	h(n)：贪婪搜索使用的启发值函数，或者说估计前进代价函数。
	f(n)：A*搜索使用的估计总代价函数。F(n)=g(n)+h(n)
在回答一个“好的”启发式由什么构成这个问题之前，我们必须先抛开我们使用的启发式函数，思考一下A*是否保持了它的完备性和最优性的特点。的确，很容易就能找到失去了这两个黄金特点的启发式。举个例子，考虑一下启发函数h(n)=1-g(n)。先不谈搜索问题，用这个启发式能得到
f(n)=g(n)+h(n)
                    =g(n)+(1-g(n))
 =1             
于是，这样的一个启发式将A*退化为了BFS，所有代价都相等了。我们之前已经说明了，BFS在边的权重不恒定的通常情况下不能保证是最优的。
使用A*树搜索时，最优性所需的条件称为可纳性（admissibility）。可纳性约束表明，用一个可纳的启发式估算的值既不是负的，也不是高估的（overestimate）。定义h*(n)为从一个给定节点n到达目标状态的真正的最佳前进代价，我们能将可纳性约束数学表示为：
∀n,0≤h(n)≤h^* (n)
定理. 对于一个给定的搜索问题，如果一个启发式函数h满足可纳性约束，使用含有h的A*树搜索能得到最优解。
证明. 假设两个可以到达的目标状态，最优目标A和次优目标B在一个给定的搜索问题的搜索树中。因为可以从初始状态到达A，A的某个祖先节点n（有可能是A本身）现在一定在边缘上。用以下三个陈述，我们可以断定n会在B之前被选来扩展：
	g(A)<g(B)。因为A是最优而B是次优，我们能得出A到达起始状态的后退代价低于B。
	h(A)=h(B)=0，因为已知我们的启发式满足可纳性约束。因为A和B都是目标状态，从A或B到达目标状态的真实最优代价就是h^* (n)=0；因此0≤h(n)≤0。
	f(n)≤f(A)，因为，虽然h有可纳性，f(n)=g(n)+h(n)≤g(n)+h^* (n)=g(A)=f(A)。穿过节点n的总代价最大是A的真实后退代价，也就是A的总代价。

我们通过陈述1和2得到f(A)<f(B)：
f(A)=g(A)+h(A)<g(B)=g(B)+h(B)=f(B)
将上面得出的不等式与陈述3结合，可以得到一个简单的结论：
f(n)≤f(A)⋀f(A)<f(B)⟹f(n)<f(B)
由此，我们知道n在B之前被扩展。因为我们已经证明了对任意n均有这个结论，我们能得出结论A所有的祖先（包括A自己）都在B之前扩展。

我们在上面发现树搜索有一个问题，那就是有些情况下它可能会找不到解，在状态空间图中陷入同一个环中无限地搜索下去。即使是在我们的搜索技术不涉及这样一个无限循环的情况下，因为有多个路径能到达同一个点，我们经常会多次访问同一个节点。这导致工作量指数上升，而自然地解决方案只是简单地跟踪哪些状态已经扩展过，并且永远不再扩展它们。更明确地讲，在使用你选择的方法的同时维持一个“封闭”的扩展节点集。然后，确保每一个节点在扩展前不在这个集合中，并且在扩展后将其加入集合里。经过这种优化的树搜索成为图搜索（graph search），其伪代码如下：
 
	注意在实现时，很重要的一点是将封闭集存储为一个不相交集合而不是一个队列。将它存储为队列需要花费O(n)个操作来检查资格（membership），这会抵消图搜索本来的优势。关于图搜索，另一个需要注意的是即使是在可纳的启发式下，它也会破坏A*的最优性。思考一下下面这个简单的状态空间图和相应的搜索树，启发值和权重都已标出：
 
	在上面这个例子中，最佳路径显然是S→A→C→G，得到总路径代价为1+1+3=5.仅有的另一条到达目标的路径，S→B→C→G的代价为1+2+3=6.然而，因为节点A的启发值比B大得多，节点C首先作为节点B的孩子沿着次优路径扩展。然后它才被放入“封闭”集，所以A*在把它当做A的孩子访问它时无法重新扩展它，导致它永远无法找到最优解。于是，为了维持A*搜索下的完备性和最优性，我们需要一个比可纳性更强的性质，一致性（consistency）。一致性的核心思想在于，我们不仅仅强制让启发式算法低估从任意给定节点到目标的总距离，还低估了图中每一条边的代价/权重。由启发式函数度量的边的代价只是两个连接的节点的启发值的差异。一致性约束的数学表示如下：
∀A,C h(A)-h(C)≤cost(A,C)

定理. 对于一个给定的搜索问题，如果启发式函数h满足一致性约束，对这个搜索问题使用有h的A*图搜索能得到一个最优解。
证明.为了证明上述理论，我们先证明在使用一个有恒定启发式的A*图搜索时，无论何时我们移除一个节点来进行扩展，我们都已经找到了通往那个节点的最佳路径。
	使用一致性约束，我们能展示根据任何计划节点的f(n)值都不会下降。定义两个节点n和n’，n’是n的后继。那么：
 
	如果对于一条路径上的所有父子节点对(n,n')都有f(n')≥f(n)，那么在那条路径上f(n)的值肯定都不是递减的。我们可以发现上面的图破坏了f(A)和f(C)之间的这一规则。有了这个信息，我们现在能看出一个节点无论何时被移除来进行扩展，它的最佳路径都已被找到。反向假设这是错的——当n从边缘被移除时，找到的通往n的路径不是最优的。这意味着一定有一个n的祖先n''位于没有被扩展过的边缘上,但是却在通向n的最佳路径上。不存在的！我们已经说了，沿着一条路径的f值不是递减的，所以n''一定在n之前就已经被移除来进行扩展了。
	现在要完成我们的证明只需要再说明一个最优目标A一定会在任何次优目标B之前被移除来进行扩展。这只是个小问题，因为h(A)=h(B)=0，所以有
f(A)=g(A)<g(B)=f(B)
这与我们之前证明在可纳性约束下的A*树搜索具有最优性是一个道理。于是，我们能得到结论：在一致性启发式下A*图搜索具有最优性。
	在我们继续之前，上面的讨论中有几个重点：对于可纳/一致的启发式，要使其有效，根据定义，h(G)=0对任何目标状态G都必须成立。此外，一致性不仅仅是比可纳性更强的约束，一致性也意味着可纳性。这仅仅源于一个事实：如果没有被高估的边缘代价（一致性保证了这一点），那么从任何节点到目标的总估计代价也不会被高估。
	下面这个由三个节点构成的网络是一个可纳但不一致的启发式例子：
 
红色虚线代表着总估计目标距离。如果h(A)=4,那么这个启发式满足可纳性，因为从A到目标的距离满足4≥h(A)，同样的h(C)=1≤3。然而，从A到C的启发式代价是h(A)-h(C)=4-1=3。我们的启发式估算A到C距离为3，而实际值为cost(A,C)=1，比估计值要小。又因为h(A)-h(C)!≤cost(A,C)，这个启发式不满足一致性。然而，对于h(A)=2运行同样的计算能得到h(A)-h(C)=2-1=1≤cost(A,C)。因此，使用h(A)=2能让我们的启发式具有一致性。

### Dominance 支配/优势
	现在我们已经建立了可纳性和一致性的性质以及它们在保持A*搜索的最优性中扮演的角色，我们能够回到我们最初的问题，创建“好”的启发式以及如何比较启发式之间的优劣。衡量这个的标准就是支配/优势（dominance）。如果启发式a相对于启发式b而言有优势，那么对状态空间图中的所有节点，a的估计目标距离都bib要好。数学表示为
∀n:h_a (n)≥h_b (n)
	优势能非常直观地表示一个启发式比另一个好的概念——如果一个可纳/一致的启发式对另一个有优势，它肯定更好，因为它总是能更准确地估计从任何给定状态到目标的距离。除此之外，微启发式（trivial heuristic）被定义为h(n)=0，使用它会将A*搜索退化为UCS。所有可纳启发式都比这个微启发式有优势。对于一个搜索问题，在搜索问题中通常在半网格（semi-lattice）的基础上加入微启发式，在半网格基础上又加入了一个优势等级序列。下面是一个结合了不同启发式h_a，h_b和h_c的半网格，它们的范围是从最底下的微启发式到最顶端的精确目标距离。
 
	一般地，应用于多个可纳启发式的最大函数同样总是可纳的。这只是启发式算法为任意给定的由可纳条件约束的状态输出的所有值中的一种结果，0≤h(n)≤h^* (n)。在这个范围内的最大数也必须落在同样的范围内。对于多个一致启发式，同样的情况也很容易被证明。为任何给定的搜索问题生成多个可纳/一致启发式，并且计算由它们输出的最大值来生成一个相比较它们中的任何一个都有优势（也更好）的启发式，这是一个惯例。

# 总结
在本章笔记中，我们讨论了搜索问题，我们将其分为了四个部分：状态空间、后继函数、起始状态和目标状态。有多种走索技术可以用于解决搜索问题，包括但不限于我们在CS188中学习的5种：
	BFS宽度优先搜索
	DFS深度优先搜索
	UCS一致代价搜索
	贪婪搜索
	A*搜索
前三种搜索技术都属于无信息搜索（uninformed search），而后两种都是通过启发式（heuristics）来估计目标距离并完善性能的有信息搜索（informed search）。
